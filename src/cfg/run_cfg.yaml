scientist_llm:
  name: o4-mini
  provider: openai
  generation_cfg:
    capability_generation:
      temperature: 0.7
      max_tokens: 16384
      seed: 42
    task_generation:
      temperature: 0.7
      max_tokens: 32768
      seed: 42
    task_solve:
      temperature: 0.7
      max_tokens: 2048
      seed: 42
    judge_llm:
      temperature: 1.0
      max_tokens: 2048
      seed: 42
    task_verify:
      temperature: 0.7
      max_tokens: 2048
      seed: 42
  local_launch_cfg:
    # Number of threads to use for local LLM
    max_num_seqs: 1
    # Type of GPU to use for local LLM
    partition: "a40"
    # QoS for local LLM
    qos: "m2"
    # Time limit for local LLM
    time: "01:00:00"

subject_llm:
  name: gemini-2.5-pro-preview-05-06
  provider: google
  generation_cfg:
    temperature: 0.7
    max_tokens: 2048
    seed: 42
  local_launch_cfg:
    # Number of threads to use for local LLM
    max_num_seqs: 50
    # Type of GPU to use for local LLM
    partition: "a40"
    # QoS for local LLM
    qos: "m2"
    # # Account for local LLM
    # account: "deadline"
    # Time limit for local LLM
    time: "01:00:00"

prompt_cfg:
  sys_msg: Complete the given task to the best of your ability.

capabilities_cfg:
  capabilities_dir: /fs01/projects/aieng/public/ace/artifacts
  results_dir: gs://ace-artifacts
  inspect_evals_dir: /fs01/projects/aieng/public/ace/inspect_evals/src/ace_evals
  domain: math
  # Method used to generate capabilities
  method: "hierarchical"
  # Number of seed capabilities to use for initial capability generation
  # Set to -1 to use all seed capabilities
  num_seed_capabilities: 1
  # Number of initial capabilities to generate using the scientist LLM
  num_gen_capabilities: 100
  # Buffer for capability generation
  num_gen_capabilities_buffer: 0.2
  # Number of capability areas to generate
  num_capability_areas: 10
  # Number of initial capabilities to generate per run
  num_gen_capabilities_per_run: 5
  # Number of tasks to generate for each capability
  num_gen_tasks_per_capability: 100
  # Buffer for task generation
  num_gen_tasks_buffer: 0.2
  # Set this flag to true to use representative tasks
  # as few shot examples for task generation
  task_gen_few_shot: true
  # Number of tasks to evaluate for each capability
  # Set to -1 to evaluate all tasks
  num_eval_tasks_per_capability: -1
  # Number of retries for each run of capability generation
  capabilities_gen_retry_attempts: 3
  tasks_gen_retry_attempts: 3
  # Concurrency for task solving and verification
  concurrency_task_solver: 50
  concurrency_task_verifier: 50
  concurrency_task_eval: 50
  # # Inspect evals config
  # inspect_eval_log_samples: false
  # inspect_eval_log_realtime: false
  # inspect_eval_score: false
  # inspect_eval_score_display: false


lbo_cfg:
  # Number of capabilities to generate using LBO
  num_lbo_runs: 1
  # Type of LBO pipeline to use
  pipeline_id: "no_discovery" # "no_discovery" or "discover_new"
  # Train args for 'nearest_neighbor' pipeline
  train_frac: 0.5
  min_train_size: 10
  # Acquisition function that guides selecting the next query point.
  # For now, only "variance" is supported.
  # TODO: Add other acquisition functions.
  acquisition_function: "variance"

embedding_cfg:
  # The embedding model name used to generate capability embeddings used for filtering.
  embedding_model: "text-embedding-3-small" # "text-embedding-3-small" or "text-embedding-3-large"
  embedding_size: 512
  # The cosine similarity threshold for filtering capabilities based on their embeddings.
  filtering_similarity_threshold: 0.85

dimensionality_reduction_cfg:
  # dimensionality reduction method generates the low dimensional encodings.
  reduce_dimensionality_method: "t-sne" # "t-sne" or "cut-embedding".
  reduced_dimensionality_size: 2

exp_cfg:
  # Set this flag to true to run test experiments during development
  seed: 37
  trial_run: false
  exp_id:

defaults:
  - _self_
  - capabilities: math
