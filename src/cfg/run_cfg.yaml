scientist_llm:
  name: gpt-4o-mini
  generation_cfg:
    capability_generation:
      temperature: 0.7
      max_tokens: 64
    task_generation:
      temperature: 0.7
      max_tokens: 64
    task_solve:
      temperature: 0.7
      max_tokens: 64

subject_llm:
  name: gpt-4o-mini # Meta-Llama-3.1-70B-Instruct
  generation_cfg:
    temperature: 0.7
    max_tokens: 8

prompt_cfg:
  sys_msg: Complete the given task to the best of your ability.

capabilities_cfg:
  capabilities_dir: /fs01/projects/aieng/public/ace/artifacts
  results_dir: gs://ace-artifacts
  inspect_evals_dir: /fs01/projects/aieng/public/ace/inspect_evals/src/ace_evals
  domain: math
  # Number of seed capabilities to use for initial capability generation
  # Set to -1 to use all seed capabilities
  num_seed_capabilities: -1
  # Number of initial capabilities to generate using the scientist LLM
  num_gen_capabilities: 4
  # Number of initial capabilities to generate per run
  num_gen_capabilities_per_run: 2
  # Number of tasks to generate for each capability
  num_gen_tasks_per_capability: 1
  # Set this flag to true to use representative tasks
  # as few shot examples for task generation
  task_gen_few_shot: true
  # Number of tasks to evaluate for each capability
  # Set to -1 to evaluate all tasks
  num_eval_tasks_per_capability: 1

lbo_cfg:
  # Number of capabilities to generate using LBO
  num_lbo_runs: 1
  # Type of LBO pipeline to use
  pipeline_id: "discover_new" # "nearest_neighbor" or "discover_new"
  # Train args for 'nearest_neighbor' pipeline
  train_frac: 0.5
  min_train_size: 10
  # Acquisition function that guides selecting the next query point.
  # For now, only "variance" is supported.
  # TODO: Add other acquisition functions.
  acquisition_function: "variance"

exp_cfg:
  # Set this flag to true to run test experiments during development
  trial_run: true

defaults:
  - _self_
  - capabilities: math
